import numpy as np

data = np.load("./train.npz")
print(data)
print(data.files)
--> <numpy.lib.npyio.NpzFile object at 0x000001D1CEC3A250>
['x', 'y']

x = data['x']
y = data['y']
print(y)
-->[3 3 2 ... 3 1 1]

import tensorflow as tf
from tensorflow import keras
from keras import Sequential, Input
from keras.layers import Dense
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x ,y , test_size=0.2, random_state=42)
print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
-> (960, 224, 224)
(240, 224, 224)

from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout

model = Sequential()


model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())

model.add(Dense(128, activation='relu'))
model.add(BatchNormalization())

model.add(Dense(32, activation='relu'))
model.add(BatchNormalization())

model.add(Dense(4, activation='softmax'))
model.summary()

-> Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 222, 222, 32)      320       
                                                                 
 max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         
 D)                                                              
                                                                 
 conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         
 g2D)                                                            
                                                                 
 conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     
                                                                 
 max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         
 g2D)                                                            
                                                                 
 flatten (Flatten)           (None, 86528)             0         
                                                                 
 dense (Dense)               (None, 128)               11075712  
                                                                 
 batch_normalization (Batch  (None, 128)               512       
 Normalization)                                                  
                                                                 
 dense_1 (Dense)             (None, 32)                4128      
                                                                 
 batch_normalization_1 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 dense_2 (Dense)             (None, 4)                 132       
                                                                 
=================================================================
Total params: 11173284 (42.62 MB)
Trainable params: 11172964 (42.62 MB)
Non-trainable params: 320 (1.25 KB)

---- 
model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(Flatten())

model.add(Dense(128, activation='relu'))
model.add(BatchNormalization())

model.add(Dense(32, activation='relu'))
model.add(BatchNormalization())

model.add(Dense(4, activation='softmax'))
model.summary()
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_3 (Conv2D)           (None, 222, 222, 32)      320       
                                                                 
 max_pooling2d_3 (MaxPoolin  (None, 111, 111, 32)      0         
 g2D)                                                            
                                                                 
 conv2d_4 (Conv2D)           (None, 109, 109, 64)      18496     
                                                                 
 max_pooling2d_4 (MaxPoolin  (None, 54, 54, 64)        0         
 g2D)                                                            
                                                                 
 conv2d_5 (Conv2D)           (None, 52, 52, 128)       73856     
                                                                 
 flatten_1 (Flatten)         (None, 346112)            0         
                                                                 
 dense_3 (Dense)             (None, 128)               44302464  
                                                                 
 batch_normalization_2 (Bat  (None, 128)               512       
 chNormalization)                                                
                                                                 
 dense_4 (Dense)             (None, 32)                4128      
                                                                 
 batch_normalization_3 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 dense_5 (Dense)             (None, 4)                 132       
                                                                 
=================================================================
Total params: 44400036 (169.37 MB)
Trainable params: 44399716 (169.37 MB)
Non-trainable params: 320 (1.25 KB)


---- Early Stopping 추가한 Model
# Early Stopping 콜백 추가
from keras.callbacks import EarlyStopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# 모델 컴파일
from keras.optimizers import Adam
model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# 모델 훈련
model.fit(x_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])
model.evaluate(x_test_scaled, y_test)
8/8 [==============================] - 5s 576ms/step - loss: 0.6502 - accuracy: 0.7917
[0.6502329707145691, 0.7916666865348816]


data_test = np.load("./test.npz")

print(data_test.files)
x_testset = data_test['x']

x_testset
-> 
array([[[217, 217, 218, ..., 216, 216, 216],
        [217, 218, 221, ..., 225, 214, 215],
        [215, 219, 221, ..., 221, 218, 219],
        ...,
        [220, 216, 211, ..., 211, 206, 204],
        [216, 216, 213, ..., 202, 209, 208],
        [216, 212, 212, ..., 209, 208, 211]],

       [[231, 228, 230, ..., 234, 237, 233],
        [227, 223, 235, ..., 231, 235, 230],
        [224, 226, 227, ..., 237, 231, 230],
        ...,
        [222, 213, 210, ..., 228, 228, 224],
        [218, 216, 220, ..., 228, 228, 222],
        [220, 221, 224, ..., 219, 232, 228]],

       [[188, 194, 190, ..., 223, 214, 211],
        [182, 189, 190, ..., 220, 219, 222],
        [200, 197, 190, ..., 212, 207, 217],
        ...,
        [192, 196, 198, ..., 212, 212, 203],
        [195, 195, 195, ..., 209, 212, 214],
        [196, 197, 201, ..., 204, 207, 212]],

       ...,

       [[249, 254, 248, ..., 254, 248, 248],
        [249, 252, 251, ..., 253, 254, 252],
        [252, 251, 251, ..., 253, 252, 255],
        ...,
        [249, 245, 245, ..., 244, 247, 241],
        [250, 246, 246, ..., 247, 246, 250],
        [248, 248, 250, ..., 245, 252, 249]],

       [[230, 230, 228, ..., 222, 215, 215],
        [232, 230, 229, ..., 218, 217, 224],
        [231, 235, 234, ..., 216, 219, 216],
        ...,
        [227, 227, 224, ..., 212, 207, 208],
        [227, 229, 225, ..., 210, 204, 211],
        [228, 222, 223, ..., 211, 207, 213]],

       [[193, 202, 189, ..., 193, 208, 193],
        [196, 203, 202, ..., 200, 203, 197],
        [202, 199, 206, ..., 201, 204, 190],
        ...,
        [202, 202, 198, ..., 183, 184, 190],
        [200, 200, 202, ..., 181, 194, 190],
        [200, 200, 196, ..., 185, 184, 194]]], dtype=uint8)

x_testset_scaled = x_testset / 255.0
x_testset_scaled
-> array([[[0.85098039, 0.85098039, 0.85490196, ..., 0.84705882,
         0.84705882, 0.84705882],
        [0.85098039, 0.85490196, 0.86666667, ..., 0.88235294,
         0.83921569, 0.84313725],
        [0.84313725, 0.85882353, 0.86666667, ..., 0.86666667,
         0.85490196, 0.85882353],
        ...,
        [0.8627451 , 0.84705882, 0.82745098, ..., 0.82745098,
         0.80784314, 0.8       ],
        [0.84705882, 0.84705882, 0.83529412, ..., 0.79215686,
         0.81960784, 0.81568627],
        [0.84705882, 0.83137255, 0.83137255, ..., 0.81960784,
         0.81568627, 0.82745098]],

       [[0.90588235, 0.89411765, 0.90196078, ..., 0.91764706,
         0.92941176, 0.91372549],
        [0.89019608, 0.8745098 , 0.92156863, ..., 0.90588235,
         0.92156863, 0.90196078],
        [0.87843137, 0.88627451, 0.89019608, ..., 0.92941176,
         0.90588235, 0.90196078],
        ...,
        [0.87058824, 0.83529412, 0.82352941, ..., 0.89411765,
         0.89411765, 0.87843137],
        [0.85490196, 0.84705882, 0.8627451 , ..., 0.89411765,
         0.89411765, 0.87058824],
        [0.8627451 , 0.86666667, 0.87843137, ..., 0.85882353,
         0.90980392, 0.89411765]],

       [[0.7372549 , 0.76078431, 0.74509804, ..., 0.8745098 ,
         0.83921569, 0.82745098],
        [0.71372549, 0.74117647, 0.74509804, ..., 0.8627451 ,
         0.85882353, 0.87058824],
        [0.78431373, 0.77254902, 0.74509804, ..., 0.83137255,
         0.81176471, 0.85098039],
        ...,
        [0.75294118, 0.76862745, 0.77647059, ..., 0.83137255,
         0.83137255, 0.79607843],
        [0.76470588, 0.76470588, 0.76470588, ..., 0.81960784,
         0.83137255, 0.83921569],
        [0.76862745, 0.77254902, 0.78823529, ..., 0.8       ,
         0.81176471, 0.83137255]],

       ...,

       [[0.97647059, 0.99607843, 0.97254902, ..., 0.99607843,
         0.97254902, 0.97254902],
        [0.97647059, 0.98823529, 0.98431373, ..., 0.99215686,
         0.99607843, 0.98823529],
        [0.98823529, 0.98431373, 0.98431373, ..., 0.99215686,
         0.98823529, 1.        ],
        ...,
        [0.97647059, 0.96078431, 0.96078431, ..., 0.95686275,
         0.96862745, 0.94509804],
        [0.98039216, 0.96470588, 0.96470588, ..., 0.96862745,
         0.96470588, 0.98039216],
        [0.97254902, 0.97254902, 0.98039216, ..., 0.96078431,
         0.98823529, 0.97647059]],

       [[0.90196078, 0.90196078, 0.89411765, ..., 0.87058824,
         0.84313725, 0.84313725],
        [0.90980392, 0.90196078, 0.89803922, ..., 0.85490196,
         0.85098039, 0.87843137],
        [0.90588235, 0.92156863, 0.91764706, ..., 0.84705882,
         0.85882353, 0.84705882],
        ...,
        [0.89019608, 0.89019608, 0.87843137, ..., 0.83137255,
         0.81176471, 0.81568627],
        [0.89019608, 0.89803922, 0.88235294, ..., 0.82352941,
         0.8       , 0.82745098],
        [0.89411765, 0.87058824, 0.8745098 , ..., 0.82745098,
         0.81176471, 0.83529412]],

       [[0.75686275, 0.79215686, 0.74117647, ..., 0.75686275,
         0.81568627, 0.75686275],
        [0.76862745, 0.79607843, 0.79215686, ..., 0.78431373,
         0.79607843, 0.77254902],
        [0.79215686, 0.78039216, 0.80784314, ..., 0.78823529,
         0.8       , 0.74509804],
        ...,
        [0.79215686, 0.79215686, 0.77647059, ..., 0.71764706,
         0.72156863, 0.74509804],
        [0.78431373, 0.78431373, 0.79215686, ..., 0.70980392,
         0.76078431, 0.74509804],
        [0.78431373, 0.78431373, 0.76862745, ..., 0.7254902 ,
         0.72156863, 0.76078431]]])

print(x_testset_scaled.shape)
-> (400, 224, 224)

x_testset_resized = np.array([resize(image, new_size) for image in x_testset_scaled])
y_pred = model.predict(x_testset_scaled)
-> 13/13 [==============================] - 2s 118ms/step

y_pred_classes = np.argmax(y_pred, axis=1)
print(y_pred_classes)
[1 2 1 3 0 1 1 1 0 3 3 0 3 1 1 2 0 2 2 1 1 3 0 2 2 3 2 1 0 1 1 0 3 3 0 1 3
 1 2 2 2 0 1 0 0 0 2 1 2 2 0 2 0 1 0 2 0 2 2 1 2 1 2 0 2 2 3 0 1 2 2 2 3 3
 3 3 2 1 0 2 0 3 3 1 0 1 3 3 3 1 2 3 1 0 1 3 1 0 2 2 2 3 3 2 0 1 2 1 0 0 0
 3 2 1 0 1 1 3 2 3 1 0 2 2 2 2 1 3 0 3 0 1 0 2 1 3 3 1 2 1 2 0 2 0 3 0 2 1
 0 2 0 0 1 1 0 0 2 1 0 3 0 2 1 3 1 3 2 1 3 1 0 3 3 0 1 1 0 3 3 2 2 0 1 1 0
 0 2 3 0 1 1 3 2 2 3 3 3 3 0 0 2 0 0 0 3 2 0 3 1 3 3 0 1 0 3 3 2 0 0 0 1 1
 2 3 1 2 1 2 3 0 0 3 3 3 2 1 0 2 2 1 1 1 1 2 1 0 2 1 3 1 3 0 2 2 1 3 1 3 3
 3 0 1 2 3 1 1 2 1 2 1 3 1 0 1 3 0 1 3 2 2 2 2 1 1 1 3 1 2 0 1 2 2 2 3 3 2
 1 2 0 3 0 0 1 2 0 3 2 2 3 1 3 0 3 3 2 2 0 0 0 1 2 3 0 2 0 2 2 0 1 3 0 2 2
 1 2 0 1 0 2 0 0 0 2 1 0 1 0 2 3 0 3 1 1 1 3 0 3 0 1 0 0 0 3 0 0 0 1 0 0 2
 3 1 0 0 3 3 3 1 0 2 0 3 0 1 2 1 2 3 3 3 3 0 2 0 1 0 0 3 3 1]

print(len(y_pred_classes))
-> 400

for i in y_pred_classes:
    print(i)
unique_values, counts = np.unique(y_pred_classes, return_counts=True)

for value, count in zip(unique_values, counts):
    print(f"{value}: {count}개")
-> 0: 108개
1: 101개
2: 98개
3: 93개

--------------------------------------------------RandomForest 이용
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
# Random Forest 모델 생성
model_new = RandomForestClassifier(n_estimators=100, random_state=42)
# 모델 학습
model_new.fit(x_train.reshape(x_train_scaled.shape[0], -1), y_train)
y_pred_forest = model_new.predict(x_test.reshape(x_test.shape[0], -1))
y_pred_forest
-> array([3, 0, 0, 1, 2, 1, 0, 0, 3, 0, 0, 2, 2, 1, 0, 1, 1, 0, 3, 2, 3, 0,
       0, 2, 0, 3, 2, 3, 1, 0, 3, 2, 0, 2, 1, 2, 1, 2, 2, 2, 3, 0, 2, 3,
       1, 1, 3, 1, 0, 1, 3, 0, 1, 1, 3, 3, 1, 1, 0, 3, 0, 3, 2, 0, 0, 3,
       3, 1, 3, 2, 3, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 2, 1, 1, 3, 1, 2,
       0, 1, 1, 2, 0, 2, 0, 2, 1, 1, 0, 1, 2, 0, 2, 0, 3, 3, 1, 3, 1, 3,
       3, 2, 1, 1, 2, 3, 1, 1, 2, 3, 2, 1, 1, 0, 0, 1, 1, 1, 2, 1, 0, 1,
       3, 3, 3, 1, 0, 0, 1, 3, 3, 0, 2, 3, 0, 1, 2, 2, 2, 0, 2, 1, 0, 2,
       3, 2, 3, 3, 3, 0, 0, 2, 3, 3, 2, 0, 0, 0, 2, 2, 3, 2, 0, 2, 2, 1,
       2, 2, 2, 0, 1, 2, 2, 0, 3, 2, 0, 0, 0, 2, 1, 2, 1, 2, 3, 1, 0, 0,
       3, 0, 1, 1, 3, 1, 0, 0, 3, 2, 1, 2, 3, 1, 1, 3, 3, 3, 3, 3, 1, 0,
       1, 0, 3, 3, 1, 2, 3, 3, 1, 1, 0, 1, 2, 0, 2, 2, 3, 1, 2, 2])

accuracy = accuracy_score(y_test, y_pred_forest)
print(f'Accuracy: {accuracy}')

classification_rep = classification_report(y_test, y_pred_forest)
print('Classification Report:\n', classification_rep)

-> Accuracy: 0.85
Classification Report:
               precision    recall  f1-score   support

           0       0.75      0.92      0.83        50
           1       0.88      0.89      0.88        64
           2       0.88      0.84      0.86        61
           3       0.89      0.77      0.83        65

    accuracy                           0.85       240
   macro avg       0.85      0.85      0.85       240
weighted avg       0.86      0.85      0.85       240

model_new.predict(x_testset_scaled.reshape(x_testset_scaled.shape[0], -1))
-> array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
       3, 3, 3, 3])
0: 103게
1: 102게
2: 96게
3: 99게






